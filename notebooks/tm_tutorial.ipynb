{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook follows the tutorial from this [post](https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24) by Susan Li."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "np.random.seed(2018)\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "nltk.download('wordnet')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/brianesamson/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"../raw/abcnews-date-text.csv\", error_bad_lines=False)\n",
        "data_text = data[['headline_text']]\n",
        "data_text['index'] = data_text.index\n",
        "documents = data_text\n",
        "\ndocuments"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": [
              "                                             headline_text    index\n",
              "0        aba decides against community broadcasting lic...        0\n",
              "1           act fire witnesses must be aware of defamation        1\n",
              "2           a g calls for infrastructure protection summit        2\n",
              "3                 air nz staff in aust strike for pay rise        3\n",
              "4            air nz strike to affect australian travellers        4\n",
              "5                        ambitious olsson wins triple jump        5\n",
              "6               antic delighted with record breaking barca        6\n",
              "7        aussie qualifier stosur wastes four memphis match        7\n",
              "8             aust addresses un security council over iraq        8\n",
              "9               australia is locked into war timetable opp        9\n",
              "10       australia to contribute 10 million in aid to iraq       10\n",
              "11       barca take record as robson celebrates birthda...       11\n",
              "12                              bathhouse plans move ahead       12\n",
              "13           big hopes for launceston cycling championship       13\n",
              "14                  big plan to boost paroo water supplies       14\n",
              "15                  blizzard buries united states in bills       15\n",
              "16          brigadier dismisses reports troops harassed in       16\n",
              "17          british combat troops arriving daily in kuwait       17\n",
              "18              bryant leads lakers to double overtime win       18\n",
              "19                bushfire victims urged to see centrelink       19\n",
              "20         businesses should prepare for terrorist attacks       20\n",
              "21         calleri avenges final defeat to eliminate massu       21\n",
              "22                 call for ethanol blend fuel to go ahead       22\n",
              "23                  carews freak goal leaves roma in ruins       23\n",
              "24                            cemeteries miss out on funds       24\n",
              "25       code of conduct toughens organ donation regula...       25\n",
              "26            commonwealth bank cuts fixed home loan rates       26\n",
              "27                  community urged to help homeless youth       27\n",
              "28        council chief executive fails to secure position       28\n",
              "29         councillor to contest wollongong as independent       29\n",
              "...                                                    ...      ...\n",
              "1103635        nepal bans solo climbers from mount everest  1103635\n",
              "1103636     new years eve 2018 celebrated around australia  1103636\n",
              "1103637  new years eve australia prepares to bring in 2018  1103637\n",
              "1103638        new years eve celebrations around the world  1103638\n",
              "1103639  new years texting data load to surge as clock ...  1103639\n",
              "1103640     north korea leader kim jong un watches concert  1103640\n",
              "1103641   now its real tourists converge on sydney harbour  1103641\n",
              "1103642  nye guide for sydney best venues public transp...  1103642\n",
              "1103643    police confirm deaths of six people in seaplane  1103643\n",
              "1103644  police officer brett forte; killed in a shooti...  1103644\n",
              "1103645     p plate driver caught 100 kph over speed limit  1103645\n",
              "1103646         protesters throw rocks at police in tehran  1103646\n",
              "1103647          remembering australian lives lost in 2017  1103647\n",
              "1103648  remount horsemanship helping veterans through ...  1103648\n",
              "1103649  roger federer rivals battling injury ahead aus...  1103649\n",
              "1103650  russian tankers fuelled north korea via transf...  1103650\n",
              "1103651  sa transport department defends major intersec...  1103651\n",
              "1103652  sea plane has crashed into the hawkesbury rive...  1103652\n",
              "1103653  search for survivors in hawkesbury sea plane c...  1103653\n",
              "1103654  second sexual assault reported at falls festiv...  1103654\n",
              "1103655  severe storms forecast for nye in south east q...  1103655\n",
              "1103656  snake catcher pleads for people not to kill re...  1103656\n",
              "1103657  south australia prepares for party to welcome ...  1103657\n",
              "1103658  strikers cool off the heat with big win in ade...  1103658\n",
              "1103659    stunning images from the sydney to hobart yacht  1103659\n",
              "1103660  the ashes smiths warners near miss liven up bo...  1103660\n",
              "1103661            timelapse: brisbanes new year fireworks  1103661\n",
              "1103662           what 2017 meant to the kids of australia  1103662\n",
              "1103663   what the papodopoulos meeting may mean for ausus  1103663\n",
              "1103664  who is george papadopoulos the former trump ca...  1103664\n",
              "\n[1103665 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ambitious olsson wins triple jump</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>antic delighted with record breaking barca</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>aussie qualifier stosur wastes four memphis match</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>aust addresses un security council over iraq</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>australia is locked into war timetable opp</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>australia to contribute 10 million in aid to iraq</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>barca take record as robson celebrates birthda...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bathhouse plans move ahead</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>big hopes for launceston cycling championship</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>big plan to boost paroo water supplies</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>blizzard buries united states in bills</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>brigadier dismisses reports troops harassed in</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>british combat troops arriving daily in kuwait</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>bryant leads lakers to double overtime win</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>bushfire victims urged to see centrelink</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>businesses should prepare for terrorist attacks</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>calleri avenges final defeat to eliminate massu</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>call for ethanol blend fuel to go ahead</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>carews freak goal leaves roma in ruins</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>cemeteries miss out on funds</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>code of conduct toughens organ donation regula...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>commonwealth bank cuts fixed home loan rates</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>community urged to help homeless youth</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>council chief executive fails to secure position</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>councillor to contest wollongong as independent</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103635</th>\n",
              "      <td>nepal bans solo climbers from mount everest</td>\n",
              "      <td>1103635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103636</th>\n",
              "      <td>new years eve 2018 celebrated around australia</td>\n",
              "      <td>1103636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103637</th>\n",
              "      <td>new years eve australia prepares to bring in 2018</td>\n",
              "      <td>1103637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103638</th>\n",
              "      <td>new years eve celebrations around the world</td>\n",
              "      <td>1103638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103639</th>\n",
              "      <td>new years texting data load to surge as clock ...</td>\n",
              "      <td>1103639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103640</th>\n",
              "      <td>north korea leader kim jong un watches concert</td>\n",
              "      <td>1103640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103641</th>\n",
              "      <td>now its real tourists converge on sydney harbour</td>\n",
              "      <td>1103641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103642</th>\n",
              "      <td>nye guide for sydney best venues public transp...</td>\n",
              "      <td>1103642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103643</th>\n",
              "      <td>police confirm deaths of six people in seaplane</td>\n",
              "      <td>1103643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103644</th>\n",
              "      <td>police officer brett forte; killed in a shooti...</td>\n",
              "      <td>1103644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103645</th>\n",
              "      <td>p plate driver caught 100 kph over speed limit</td>\n",
              "      <td>1103645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103646</th>\n",
              "      <td>protesters throw rocks at police in tehran</td>\n",
              "      <td>1103646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103647</th>\n",
              "      <td>remembering australian lives lost in 2017</td>\n",
              "      <td>1103647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103648</th>\n",
              "      <td>remount horsemanship helping veterans through ...</td>\n",
              "      <td>1103648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103649</th>\n",
              "      <td>roger federer rivals battling injury ahead aus...</td>\n",
              "      <td>1103649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103650</th>\n",
              "      <td>russian tankers fuelled north korea via transf...</td>\n",
              "      <td>1103650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103651</th>\n",
              "      <td>sa transport department defends major intersec...</td>\n",
              "      <td>1103651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103652</th>\n",
              "      <td>sea plane has crashed into the hawkesbury rive...</td>\n",
              "      <td>1103652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103653</th>\n",
              "      <td>search for survivors in hawkesbury sea plane c...</td>\n",
              "      <td>1103653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103654</th>\n",
              "      <td>second sexual assault reported at falls festiv...</td>\n",
              "      <td>1103654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103655</th>\n",
              "      <td>severe storms forecast for nye in south east q...</td>\n",
              "      <td>1103655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103656</th>\n",
              "      <td>snake catcher pleads for people not to kill re...</td>\n",
              "      <td>1103656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103657</th>\n",
              "      <td>south australia prepares for party to welcome ...</td>\n",
              "      <td>1103657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103658</th>\n",
              "      <td>strikers cool off the heat with big win in ade...</td>\n",
              "      <td>1103658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103659</th>\n",
              "      <td>stunning images from the sydney to hobart yacht</td>\n",
              "      <td>1103659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103660</th>\n",
              "      <td>the ashes smiths warners near miss liven up bo...</td>\n",
              "      <td>1103660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103661</th>\n",
              "      <td>timelapse: brisbanes new year fireworks</td>\n",
              "      <td>1103661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103662</th>\n",
              "      <td>what 2017 meant to the kids of australia</td>\n",
              "      <td>1103662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103663</th>\n",
              "      <td>what the papodopoulos meeting may mean for ausus</td>\n",
              "      <td>1103663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103664</th>\n",
              "      <td>who is george papadopoulos the former trump ca...</td>\n",
              "      <td>1103664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1103665 rows × 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatize**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "WordNetLemmatizer().lemmatize('went', pos='v')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "'go'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
        "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
        "           'traditional', 'reference', 'colonizer','plotted']\n",
        "singles = [stemmer.stem(plural) for plural in original_words]\n",
        "stemmed = pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})\n",
        "stemmed"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "   original word stemmed\n",
              "0       caresses  caress\n",
              "1          flies     fli\n",
              "2           dies     die\n",
              "3          mules    mule\n",
              "4         denied    deni\n",
              "5           died     die\n",
              "6         agreed    agre\n",
              "7          owned     own\n",
              "8        humbled   humbl\n",
              "9          sized    size\n",
              "10       meeting    meet\n",
              "11       stating   state\n",
              "12       siezing    siez\n",
              "13   itemization    item\n",
              "14   sensational  sensat\n",
              "15   traditional  tradit\n",
              "16     reference   refer\n",
              "17     colonizer   colon\n",
              "18       plotted    plot"
            ],
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original word</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>caresses</td>\n",
              "      <td>caress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flies</td>\n",
              "      <td>fli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dies</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mules</td>\n",
              "      <td>mule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>denied</td>\n",
              "      <td>deni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>died</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>agreed</td>\n",
              "      <td>agre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>owned</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>humbled</td>\n",
              "      <td>humbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sized</td>\n",
              "      <td>size</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>meeting</td>\n",
              "      <td>meet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>stating</td>\n",
              "      <td>state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>siezing</td>\n",
              "      <td>siez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>itemization</td>\n",
              "      <td>item</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sensational</td>\n",
              "      <td>sensat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>traditional</td>\n",
              "      <td>tradit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>reference</td>\n",
              "      <td>refer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>colonizer</td>\n",
              "      <td>colon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>plotted</td>\n",
              "      <td>plot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**\n",
        "\n",
        "- Tokenization\n",
        "- Lemmatization\n",
        "- Stemming\n",
        "- Remove stopwords\n",
        "- Remove words with <= 3 characters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
        "print('Original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "   \n",
        "print(words)\n",
        "print('\\n\\nTokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original document: \n",
            "['rain', 'helps', 'dampen', 'bushfires']\n",
            "\n\n",
            "Tokenized and lemmatized document: \n",
            "['rain', 'help', 'dampen', 'bushfir']\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs = documents['headline_text'].map(preprocess)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": [
              "0                      [decid, communiti, broadcast, licenc]\n",
              "1                                         [wit, awar, defam]\n",
              "2                     [call, infrastructur, protect, summit]\n",
              "3                                [staff, aust, strike, rise]\n",
              "4                       [strike, affect, australian, travel]\n",
              "5                         [ambiti, olsson, win, tripl, jump]\n",
              "6                     [antic, delight, record, break, barca]\n",
              "7              [aussi, qualifi, stosur, wast, memphi, match]\n",
              "8                      [aust, address, secur, council, iraq]\n",
              "9                                   [australia, lock, timet]\n",
              "10                     [australia, contribut, million, iraq]\n",
              "11                 [barca, record, robson, celebr, birthday]\n",
              "12                                   [bathhous, plan, ahead]\n",
              "13                     [hop, launceston, cycl, championship]\n",
              "14                       [plan, boost, paroo, water, suppli]\n",
              "15                       [blizzard, buri, unit, state, bill]\n",
              "16                 [brigadi, dismiss, report, troop, harass]\n",
              "17            [british, combat, troop, arriv, daili, kuwait]\n",
              "18                     [bryant, lead, laker, doubl, overtim]\n",
              "19                        [bushfir, victim, urg, centrelink]\n",
              "20                         [busi, prepar, terrorist, attack]\n",
              "21            [calleri, aveng, final, defeat, elimin, massu]\n",
              "22                             [ethanol, blend, fuel, ahead]\n",
              "23                    [carew, freak, goal, leav, roma, ruin]\n",
              "24                                    [cemeteri, miss, fund]\n",
              "25             [code, conduct, toughen, organ, donat, regul]\n",
              "26           [commonwealth, bank, cut, fix, home, loan, rat]\n",
              "27                   [communiti, urg, help, homeless, youth]\n",
              "28              [council, chief, execut, fail, secur, posit]\n",
              "29               [councillor, contest, wollongong, independ]\n",
              "                                 ...                        \n",
              "1103635          [nepal, ban, solo, climber, mount, everest]\n",
              "1103636                            [year, celebr, australia]\n",
              "1103637                     [year, australia, prepar, bring]\n",
              "1103638                                [year, celebr, world]\n",
              "1103639    [year, text, data, load, surg, clock, strike, ...\n",
              "1103640         [north, korea, leader, jong, watch, concert]\n",
              "1103641            [real, tourist, converg, sydney, harbour]\n",
              "1103642    [guid, sydney, best, venu, public, transport, ...\n",
              "1103643              [polic, confirm, death, peopl, seaplan]\n",
              "1103644    [polic, offic, brett, fort, kill, shoot, incid...\n",
              "1103645                 [plate, driver, catch, speed, limit]\n",
              "1103646                [protest, throw, rock, polic, tehran]\n",
              "1103647                     [rememb, australian, live, lose]\n",
              "1103648         [remount, horsemanship, help, veteran, ptsd]\n",
              "1103649    [roger, feder, rival, battl, injuri, ahead, au...\n",
              "1103650    [russian, tanker, fuel, north, korea, transfer...\n",
              "1103651    [transport, depart, defend, major, intersect, ...\n",
              "1103652                    [plane, crash, hawkesburi, river]\n",
              "1103653         [search, survivor, hawkesburi, plane, crash]\n",
              "1103654    [second, sexual, assault, report, fall, festiv...\n",
              "1103655    [sever, storm, forecast, south, east, queensland]\n",
              "1103656         [snake, catcher, plead, peopl, kill, reptil]\n",
              "1103657      [south, australia, prepar, parti, welcom, year]\n",
              "1103658                       [striker, cool, heat, adelaid]\n",
              "1103659                  [stun, imag, sydney, hobart, yacht]\n",
              "1103660    [ash, smith, warner, near, miss, liven, box, t...\n",
              "1103661                  [timelaps, brisban, year, firework]\n",
              "1103662                               [mean, kid, australia]\n",
              "1103663                     [papodopoulo, meet, mean, ausus]\n",
              "1103664           [georg, papadopoulo, trump, campaign, aid]\n",
              "Name: headline_text, Length: 1103665, dtype: object"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Bag of Words on the dataset**\n",
        "\nGet all the unique words and assign an ID to them."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 broadcast\n",
            "1 communiti\n",
            "2 decid\n",
            "3 licenc\n",
            "4 awar\n",
            "5 defam\n",
            "6 wit\n",
            "7 call\n",
            "8 infrastructur\n",
            "9 protect\n",
            "10 summit\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter words** | [Source](https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.filter_extremes.html)\n",
        "\n",
        "Filter out tokens that appear in\n",
        "\n",
        "- less than `no_below` documents (absolute number) or\n",
        "- more than `no_above` documents (fraction of total corpus size, not absolute number).\n",
        "- after (1) and (2), keep only the first `keep_n` most frequent tokens (or keep all if None)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert corpus to used the BoW IDs and count the word frequency per document**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4310]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": [
              "[(76, 1), (112, 1), (483, 1), (4014, 1)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_doc_4310 = bow_corpus[32]\n",
        "\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                                     dictionary[bow_doc_4310[i][0]], \n",
        "                                                     bow_doc_4310[i][1]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 34 (\"council\") appears 1 time.\n",
            "Word 129 (\"welcom\") appears 1 time.\n",
            "Word 130 (\"breakthrough\") appears 1 time.\n",
            "Word 131 (\"insur\") appears 1 time.\n"
          ]
        }
      ],
      "execution_count": 34,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF\n",
        "===\n",
        "\nFirst, calculate the inverse document counts for all terms in the training corpus."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "\ntfidf = models.TfidfModel(bow_corpus)"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, transform the count representations into the Tfidf space."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tfidf = tfidf[bow_corpus]"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "    \n",
        "pprint(corpus_tfidf[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.58929086447099832),\n",
            " (1, 0.38929657403503015),\n",
            " (2, 0.4964985198530063),\n",
            " (3, 0.50465203286956617)]\n"
          ]
        }
      ],
      "execution_count": 40,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA using Bag of Words\n",
        "==="
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.028*\"queensland\" + 0.021*\"hous\" + 0.020*\"school\" + 0.015*\"chang\" + 0.014*\"child\" + 0.012*\"abus\" + 0.011*\"driver\" + 0.010*\"concern\" + 0.009*\"worker\" + 0.009*\"liber\"\n",
            "Topic: 1 \n",
            "Words: 0.019*\"nation\" + 0.016*\"health\" + 0.013*\"indigen\" + 0.012*\"servic\" + 0.012*\"gold\" + 0.011*\"communiti\" + 0.011*\"feder\" + 0.011*\"help\" + 0.011*\"busi\" + 0.010*\"coast\"\n",
            "Topic: 2 \n",
            "Words: 0.016*\"china\" + 0.016*\"rural\" + 0.016*\"elect\" + 0.015*\"govern\" + 0.013*\"fight\" + 0.010*\"royal\" + 0.010*\"prison\" + 0.009*\"say\" + 0.009*\"announc\" + 0.009*\"drum\"\n",
            "Topic: 3 \n",
            "Words: 0.018*\"women\" + 0.016*\"world\" + 0.010*\"tasmanian\" + 0.010*\"record\" + 0.010*\"life\" + 0.010*\"fear\" + 0.010*\"million\" + 0.010*\"street\" + 0.010*\"violenc\" + 0.009*\"year\"\n",
            "Topic: 4 \n",
            "Words: 0.038*\"trump\" + 0.019*\"attack\" + 0.013*\"say\" + 0.013*\"kill\" + 0.013*\"train\" + 0.012*\"near\" + 0.012*\"guilti\" + 0.011*\"polit\" + 0.011*\"farm\" + 0.011*\"time\"\n",
            "Topic: 5 \n",
            "Words: 0.022*\"call\" + 0.020*\"countri\" + 0.016*\"turnbul\" + 0.016*\"water\" + 0.014*\"test\" + 0.014*\"student\" + 0.011*\"john\" + 0.011*\"parti\" + 0.010*\"meet\" + 0.009*\"energi\"\n",
            "Topic: 6 \n",
            "Words: 0.049*\"australia\" + 0.018*\"home\" + 0.015*\"final\" + 0.015*\"interview\" + 0.014*\"open\" + 0.014*\"tasmania\" + 0.013*\"win\" + 0.011*\"island\" + 0.011*\"leagu\" + 0.010*\"return\"\n",
            "Topic: 7 \n",
            "Words: 0.034*\"court\" + 0.022*\"face\" + 0.021*\"charg\" + 0.020*\"alleg\" + 0.019*\"murder\" + 0.019*\"live\" + 0.018*\"accus\" + 0.016*\"drug\" + 0.016*\"hour\" + 0.015*\"trial\"\n",
            "Topic: 8 \n",
            "Words: 0.026*\"year\" + 0.019*\"market\" + 0.017*\"famili\" + 0.015*\"rise\" + 0.014*\"high\" + 0.014*\"price\" + 0.014*\"share\" + 0.013*\"australian\" + 0.012*\"jail\" + 0.011*\"sentenc\"\n",
            "Topic: 9 \n",
            "Words: 0.038*\"polic\" + 0.027*\"sydney\" + 0.020*\"south\" + 0.019*\"adelaid\" + 0.018*\"melbourn\" + 0.017*\"crash\" + 0.017*\"perth\" + 0.017*\"death\" + 0.015*\"die\" + 0.014*\"woman\"\n"
          ]
        }
      ],
      "execution_count": 47,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA using TF-IDF\n",
        "==="
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 Word: 0.009*\"leagu\" + 0.008*\"final\" + 0.008*\"australia\" + 0.007*\"world\" + 0.007*\"christma\" + 0.006*\"sexual\" + 0.005*\"cricket\" + 0.005*\"test\" + 0.005*\"david\" + 0.005*\"jam\"\n",
            "Topic: 1 Word: 0.017*\"countri\" + 0.015*\"hour\" + 0.008*\"health\" + 0.007*\"fund\" + 0.006*\"grandstand\" + 0.005*\"sport\" + 0.005*\"abbott\" + 0.005*\"plead\" + 0.005*\"plan\" + 0.005*\"council\"\n",
            "Topic: 2 Word: 0.022*\"trump\" + 0.011*\"donald\" + 0.007*\"michael\" + 0.007*\"septemb\" + 0.007*\"friday\" + 0.006*\"andrew\" + 0.006*\"june\" + 0.005*\"capit\" + 0.004*\"presid\" + 0.004*\"bash\"\n",
            "Topic: 3 Word: 0.011*\"drum\" + 0.010*\"weather\" + 0.007*\"search\" + 0.007*\"octob\" + 0.006*\"monday\" + 0.006*\"malcolm\" + 0.006*\"stori\" + 0.006*\"miss\" + 0.006*\"polic\" + 0.005*\"rate\"\n",
            "Topic: 4 Word: 0.013*\"interview\" + 0.010*\"turnbul\" + 0.008*\"marriag\" + 0.007*\"ash\" + 0.006*\"asylum\" + 0.006*\"tuesday\" + 0.006*\"seeker\" + 0.005*\"outback\" + 0.005*\"detent\" + 0.004*\"footag\"\n",
            "Topic: 5 Word: 0.009*\"royal\" + 0.007*\"commiss\" + 0.007*\"govern\" + 0.005*\"social\" + 0.005*\"univers\" + 0.005*\"updat\" + 0.004*\"festiv\" + 0.004*\"harvest\" + 0.004*\"georg\" + 0.004*\"remov\"\n",
            "Topic: 6 Word: 0.007*\"peter\" + 0.006*\"thursday\" + 0.006*\"zealand\" + 0.005*\"farm\" + 0.005*\"bushfir\" + 0.005*\"climat\" + 0.004*\"blaze\" + 0.004*\"age\" + 0.004*\"patient\" + 0.004*\"firefight\"\n",
            "Topic: 7 Word: 0.011*\"podcast\" + 0.007*\"juli\" + 0.006*\"domest\" + 0.005*\"say\" + 0.005*\"toni\" + 0.005*\"violenc\" + 0.005*\"april\" + 0.005*\"interview\" + 0.005*\"western\" + 0.004*\"rural\"\n",
            "Topic: 8 Word: 0.015*\"market\" + 0.012*\"news\" + 0.012*\"rural\" + 0.008*\"share\" + 0.008*\"queensland\" + 0.007*\"australian\" + 0.006*\"busi\" + 0.006*\"farmer\" + 0.005*\"cattl\" + 0.005*\"nation\"\n",
            "Topic: 9 Word: 0.014*\"polic\" + 0.013*\"crash\" + 0.013*\"kill\" + 0.013*\"charg\" + 0.012*\"murder\" + 0.010*\"woman\" + 0.009*\"shoot\" + 0.009*\"death\" + 0.009*\"dead\" + 0.008*\"attack\"\n"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample classification of documents to topics\n",
        "===\n",
        "\n**Using the LDA Bag of Words model**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs[4310]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": [
              "['rain', 'help', 'dampen', 'bushfir']"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Score: 0.6199929118156433\t \n",
            "Topic: 0.019*\"nation\" + 0.016*\"health\" + 0.013*\"indigen\" + 0.012*\"servic\" + 0.012*\"gold\" + 0.011*\"communiti\" + 0.011*\"feder\" + 0.011*\"help\" + 0.011*\"busi\" + 0.010*\"coast\"\n",
            "\n",
            "Score: 0.21999980509281158\t \n",
            "Topic: 0.018*\"women\" + 0.016*\"world\" + 0.010*\"tasmanian\" + 0.010*\"record\" + 0.010*\"life\" + 0.010*\"fear\" + 0.010*\"million\" + 0.010*\"street\" + 0.010*\"violenc\" + 0.009*\"year\"\n",
            "\n",
            "Score: 0.020005155354738235\t \n",
            "Topic: 0.038*\"polic\" + 0.027*\"sydney\" + 0.020*\"south\" + 0.019*\"adelaid\" + 0.018*\"melbourn\" + 0.017*\"crash\" + 0.017*\"perth\" + 0.017*\"death\" + 0.015*\"die\" + 0.014*\"woman\"\n",
            "\n",
            "Score: 0.020001305267214775\t \n",
            "Topic: 0.022*\"call\" + 0.020*\"countri\" + 0.016*\"turnbul\" + 0.016*\"water\" + 0.014*\"test\" + 0.014*\"student\" + 0.011*\"john\" + 0.011*\"parti\" + 0.010*\"meet\" + 0.009*\"energi\"\n",
            "\n",
            "Score: 0.020000819116830826\t \n",
            "Topic: 0.028*\"queensland\" + 0.021*\"hous\" + 0.020*\"school\" + 0.015*\"chang\" + 0.014*\"child\" + 0.012*\"abus\" + 0.011*\"driver\" + 0.010*\"concern\" + 0.009*\"worker\" + 0.009*\"liber\"\n",
            "\n",
            "Score: 0.020000005140900612\t \n",
            "Topic: 0.016*\"china\" + 0.016*\"rural\" + 0.016*\"elect\" + 0.015*\"govern\" + 0.013*\"fight\" + 0.010*\"royal\" + 0.010*\"prison\" + 0.009*\"say\" + 0.009*\"announc\" + 0.009*\"drum\"\n",
            "\n",
            "Score: 0.020000001415610313\t \n",
            "Topic: 0.038*\"trump\" + 0.019*\"attack\" + 0.013*\"say\" + 0.013*\"kill\" + 0.013*\"train\" + 0.012*\"near\" + 0.012*\"guilti\" + 0.011*\"polit\" + 0.011*\"farm\" + 0.011*\"time\"\n",
            "\n",
            "Score: 0.020000001415610313\t \n",
            "Topic: 0.049*\"australia\" + 0.018*\"home\" + 0.015*\"final\" + 0.015*\"interview\" + 0.014*\"open\" + 0.014*\"tasmania\" + 0.013*\"win\" + 0.011*\"island\" + 0.011*\"leagu\" + 0.010*\"return\"\n",
            "\n",
            "Score: 0.020000001415610313\t \n",
            "Topic: 0.034*\"court\" + 0.022*\"face\" + 0.021*\"charg\" + 0.020*\"alleg\" + 0.019*\"murder\" + 0.019*\"live\" + 0.018*\"accus\" + 0.016*\"drug\" + 0.016*\"hour\" + 0.015*\"trial\"\n",
            "\n",
            "Score: 0.020000001415610313\t \n",
            "Topic: 0.026*\"year\" + 0.019*\"market\" + 0.017*\"famili\" + 0.015*\"rise\" + 0.014*\"high\" + 0.014*\"price\" + 0.014*\"share\" + 0.013*\"australian\" + 0.012*\"jail\" + 0.011*\"sentenc\"\n"
          ]
        }
      ],
      "execution_count": 49,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the LDA TFIDF model**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Score: 0.8199766278266907\t \n",
            "Topic: 0.026*\"year\" + 0.019*\"market\" + 0.017*\"famili\" + 0.015*\"rise\" + 0.014*\"high\" + 0.014*\"price\" + 0.014*\"share\" + 0.013*\"australian\" + 0.012*\"jail\" + 0.011*\"sentenc\"\n",
            "\n",
            "Score: 0.020014287903904915\t \n",
            "Topic: 0.049*\"australia\" + 0.018*\"home\" + 0.015*\"final\" + 0.015*\"interview\" + 0.014*\"open\" + 0.014*\"tasmania\" + 0.013*\"win\" + 0.011*\"island\" + 0.011*\"leagu\" + 0.010*\"return\"\n",
            "\n",
            "Score: 0.02000255137681961\t \n",
            "Topic: 0.019*\"nation\" + 0.016*\"health\" + 0.013*\"indigen\" + 0.012*\"servic\" + 0.012*\"gold\" + 0.011*\"communiti\" + 0.011*\"feder\" + 0.011*\"help\" + 0.011*\"busi\" + 0.010*\"coast\"\n",
            "\n",
            "Score: 0.020001647993922234\t \n",
            "Topic: 0.018*\"women\" + 0.016*\"world\" + 0.010*\"tasmanian\" + 0.010*\"record\" + 0.010*\"life\" + 0.010*\"fear\" + 0.010*\"million\" + 0.010*\"street\" + 0.010*\"violenc\" + 0.009*\"year\"\n",
            "\n",
            "Score: 0.02000107429921627\t \n",
            "Topic: 0.022*\"call\" + 0.020*\"countri\" + 0.016*\"turnbul\" + 0.016*\"water\" + 0.014*\"test\" + 0.014*\"student\" + 0.011*\"john\" + 0.011*\"parti\" + 0.010*\"meet\" + 0.009*\"energi\"\n",
            "\n",
            "Score: 0.02000105008482933\t \n",
            "Topic: 0.038*\"polic\" + 0.027*\"sydney\" + 0.020*\"south\" + 0.019*\"adelaid\" + 0.018*\"melbourn\" + 0.017*\"crash\" + 0.017*\"perth\" + 0.017*\"death\" + 0.015*\"die\" + 0.014*\"woman\"\n",
            "\n",
            "Score: 0.020000901073217392\t \n",
            "Topic: 0.038*\"trump\" + 0.019*\"attack\" + 0.013*\"say\" + 0.013*\"kill\" + 0.013*\"train\" + 0.012*\"near\" + 0.012*\"guilti\" + 0.011*\"polit\" + 0.011*\"farm\" + 0.011*\"time\"\n",
            "\n",
            "Score: 0.020000752061605453\t \n",
            "Topic: 0.034*\"court\" + 0.022*\"face\" + 0.021*\"charg\" + 0.020*\"alleg\" + 0.019*\"murder\" + 0.019*\"live\" + 0.018*\"accus\" + 0.016*\"drug\" + 0.016*\"hour\" + 0.015*\"trial\"\n",
            "\n",
            "Score: 0.020000675693154335\t \n",
            "Topic: 0.016*\"china\" + 0.016*\"rural\" + 0.016*\"elect\" + 0.015*\"govern\" + 0.013*\"fight\" + 0.010*\"royal\" + 0.010*\"prison\" + 0.009*\"say\" + 0.009*\"announc\" + 0.009*\"drum\"\n",
            "\n",
            "Score: 0.02000044472515583\t \n",
            "Topic: 0.028*\"queensland\" + 0.021*\"hous\" + 0.020*\"school\" + 0.015*\"chang\" + 0.014*\"child\" + 0.012*\"abus\" + 0.011*\"driver\" + 0.010*\"concern\" + 0.009*\"worker\" + 0.009*\"liber\"\n"
          ]
        }
      ],
      "execution_count": 50,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**On an unseen document**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.2895960509777069\t Topic: 0.038*\"trump\" + 0.019*\"attack\" + 0.013*\"say\" + 0.013*\"kill\" + 0.013*\"train\"\n",
            "Score: 0.21366867423057556\t Topic: 0.026*\"year\" + 0.019*\"market\" + 0.017*\"famili\" + 0.015*\"rise\" + 0.014*\"high\"\n",
            "Score: 0.21339593827724457\t Topic: 0.022*\"call\" + 0.020*\"countri\" + 0.016*\"turnbul\" + 0.016*\"water\" + 0.014*\"test\"\n",
            "Score: 0.18333330750465393\t Topic: 0.038*\"polic\" + 0.027*\"sydney\" + 0.020*\"south\" + 0.019*\"adelaid\" + 0.018*\"melbourn\"\n",
            "Score: 0.016670215874910355\t Topic: 0.016*\"china\" + 0.016*\"rural\" + 0.016*\"elect\" + 0.015*\"govern\" + 0.013*\"fight\"\n",
            "Score: 0.016668127849698067\t Topic: 0.028*\"queensland\" + 0.021*\"hous\" + 0.020*\"school\" + 0.015*\"chang\" + 0.014*\"child\"\n",
            "Score: 0.016667678952217102\t Topic: 0.049*\"australia\" + 0.018*\"home\" + 0.015*\"final\" + 0.015*\"interview\" + 0.014*\"open\"\n",
            "Score: 0.01666666753590107\t Topic: 0.019*\"nation\" + 0.016*\"health\" + 0.013*\"indigen\" + 0.012*\"servic\" + 0.012*\"gold\"\n",
            "Score: 0.01666666753590107\t Topic: 0.018*\"women\" + 0.016*\"world\" + 0.010*\"tasmanian\" + 0.010*\"record\" + 0.010*\"life\"\n",
            "Score: 0.01666666567325592\t Topic: 0.034*\"court\" + 0.022*\"face\" + 0.021*\"charg\" + 0.020*\"alleg\" + 0.019*\"murder\"\n"
          ]
        }
      ],
      "execution_count": 51,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}